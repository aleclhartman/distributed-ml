{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data\n",
    "import pyspark\n",
    "import pyspark.ml\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "\n",
    "df = spark.createDataFrame(data('tips'))\n",
    "\n",
    "train, test = df.randomSplit([0.8, 0.2], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can we stratify using randomSplit?\n",
    "df.randomSplit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no shape so zach made function\n",
    "# spark is lazy so we don't know the shape of the data\n",
    "def shape(df: pyspark.sql.DataFrame):\n",
    "    return df.count(), len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "We'll first demonstrate a regression problem: predicting the tip amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     12.69| 2.0|  Male|    No|Sat|Dinner|   2|\n",
      "|     13.37| 2.0|  Male|    No|Sat|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pyspark.ml.feature.RFormula`\n",
    "\n",
    "- `tip ~ total_bill`: predict tip based on total bill\n",
    "- `tip ~ total_bill + size`: predict tip based on total bill and size\n",
    "- `tip ~ .`: predict tip based on all the other features in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFormula_fe5c35f030b3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nb: spark's rformula does encoding\n",
    "rf = pyspark.ml.feature.RFormula(formula=\"tip ~ total_bill + size\").fit(train)\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|   features|label|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2| [8.77,2.0]|  2.0|\n",
      "|     12.69| 2.0|  Male|    No|Sat|Dinner|   2|[12.69,2.0]|  2.0|\n",
      "|     13.37| 2.0|  Male|    No|Sat|Dinner|   2|[13.37,2.0]|  2.0|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|[14.78,2.0]| 3.23|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|[14.83,2.0]| 3.02|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf.transform(train).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark.ml.feature.RFormula?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`features` and `labels` columns are the shape/name required for `pyspark.ml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|   features|label|\n",
      "+-----------+-----+\n",
      "| [8.77,2.0]|  2.0|\n",
      "|[12.69,2.0]|  2.0|\n",
      "|[13.37,2.0]|  2.0|\n",
      "|[14.78,2.0]| 3.23|\n",
      "|[14.83,2.0]| 3.02|\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_input = rf.transform(train).select('features', 'label')\n",
    "train_input.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create, fit, and use the model.\n",
    "\n",
    "**Note**: unlike `sklearn`, each step produces a new object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression_5cfb9cbb813f"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ordinary least squares\n",
    "lr = pyspark.ml.regression.LinearRegression()\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\n",
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\n",
      "epsilon: The shape parameter to control the amount of robustness. Must be > 1.0. Only valid when loss is huber (default: 1.35)\n",
      "featuresCol: features column name. (default: features)\n",
      "fitIntercept: whether to fit an intercept term. (default: True)\n",
      "labelCol: label column name. (default: label)\n",
      "loss: The loss function to be optimized. Supported options: squaredError, huber. (default: squaredError)\n",
      "maxIter: max number of iterations (>= 0). (default: 100)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "regParam: regularization parameter (>= 0). (default: 0.0)\n",
      "solver: The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (default: auto)\n",
      "standardization: whether to standardize the training features before fitting the model. (default: True)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 1e-06)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "print(lr.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+------------------+\n",
      "|   features|label|        prediction|\n",
      "+-----------+-----+------------------+\n",
      "| [8.77,2.0]|  2.0|1.9717337092055747|\n",
      "|[12.69,2.0]|  2.0|  2.28547899247938|\n",
      "|[13.37,2.0]|  2.0| 2.339904194679938|\n",
      "|[14.78,2.0]| 3.23|2.4527564521840364|\n",
      "|[14.83,2.0]| 3.02| 2.456758305287019|\n",
      "+-----------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_fit = lr.fit(train_input)\n",
    "lr_fit.transform(train_input).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might be tempting to do the following\n",
    "## This Will Not Work!!!!\n",
    "# lr = pyspark.ml.regression.LinearRegression()\n",
    "# lr.fit(train_input)\n",
    "# lr.transform(train_input)\n",
    "\n",
    "# each step in spark needs a new object unlike sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.ml.regression.LinearRegressionTrainingSummary at 0x7f94e6c68f50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_fit.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.44244602311951, 0.9975913515122248)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_fit.summary.r2, lr_fit.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coefficientStandardErrors',\n",
       " 'degreesOfFreedom',\n",
       " 'devianceResiduals',\n",
       " 'explainedVariance',\n",
       " 'featuresCol',\n",
       " 'labelCol',\n",
       " 'meanAbsoluteError',\n",
       " 'meanSquaredError',\n",
       " 'numInstances',\n",
       " 'objectiveHistory',\n",
       " 'pValues',\n",
       " 'predictionCol',\n",
       " 'predictions',\n",
       " 'r2',\n",
       " 'r2adj',\n",
       " 'residuals',\n",
       " 'rootMeanSquaredError',\n",
       " 'tValues',\n",
       " 'totalIterations']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reminder: explainedVariance == r_squared\n",
    "[x for x in dir(lr_fit.summary) if not x.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we do on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+-----+------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|   features|label|        prediction|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+------------------+\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|[10.27,2.0]| 1.71| 2.091789302295041|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|[10.33,3.0]| 1.67|2.3597556280076217|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|[10.34,3.0]| 1.66| 2.360555998628218|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|[15.04,2.0]| 1.96| 2.473566088319544|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_input = rf.transform(test) # transforming test using r formula object\n",
    "lr_fit.transform(test_input).show(4) # predicting using linear regression object fit on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0581350816287596"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creat the thing\n",
    "evaluator = pyspark.ml.evaluation.RegressionEvaluator()\n",
    "\n",
    "# use the thing\n",
    "rmse = evaluator.evaluate(lr_fit.transform(test_input))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Predict time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     12.69| 2.0|  Male|    No|Sat|Dinner|   2|\n",
      "|     13.37| 2.0|  Male|    No|Sat|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+----+------+----+-----------+-----+\n",
      "|total_bill| tip|   sex|smoker| day|  time|size|   features|label|\n",
      "+----------+----+------+------+----+------+----+-----------+-----+\n",
      "|      8.77| 2.0|  Male|    No| Sun|Dinner|   2| [8.77,2.0]|  0.0|\n",
      "|     12.69| 2.0|  Male|    No| Sat|Dinner|   2|[12.69,2.0]|  0.0|\n",
      "|     13.37| 2.0|  Male|    No| Sat|Dinner|   2|[13.37,2.0]|  0.0|\n",
      "|     14.78|3.23|  Male|    No| Sun|Dinner|   2|[14.78,2.0]|  0.0|\n",
      "|     14.83|3.02|Female|    No| Sun|Dinner|   2|[14.83,2.0]|  0.0|\n",
      "|     15.42|1.57|  Male|    No| Sun|Dinner|   2|[15.42,2.0]|  0.0|\n",
      "|     16.29|3.71|  Male|    No| Sun|Dinner|   3|[16.29,3.0]|  0.0|\n",
      "|     16.97| 3.5|Female|    No| Sun|Dinner|   3|[16.97,3.0]|  0.0|\n",
      "|     16.99|1.01|Female|    No| Sun|Dinner|   2|[16.99,2.0]|  0.0|\n",
      "|     17.81|2.34|  Male|    No| Sat|Dinner|   4|[17.81,4.0]|  0.0|\n",
      "|     17.92|4.08|  Male|    No| Sat|Dinner|   2|[17.92,2.0]|  0.0|\n",
      "|     19.65| 3.0|Female|    No| Sat|Dinner|   2|[19.65,2.0]|  0.0|\n",
      "|     19.82|3.18|  Male|    No| Sat|Dinner|   2|[19.82,2.0]|  0.0|\n",
      "|     20.29|2.75|Female|    No| Sat|Dinner|   2|[20.29,2.0]|  0.0|\n",
      "|     20.65|3.35|  Male|    No| Sat|Dinner|   3|[20.65,3.0]|  0.0|\n",
      "|     21.01| 3.5|  Male|    No| Sun|Dinner|   3|[21.01,3.0]|  0.0|\n",
      "|     21.58|3.92|  Male|    No| Sun|Dinner|   2|[21.58,2.0]|  0.0|\n",
      "|      21.7| 4.3|  Male|    No| Sat|Dinner|   2| [21.7,2.0]|  0.0|\n",
      "|     24.59|3.61|Female|    No| Sun|Dinner|   4|[24.59,4.0]|  0.0|\n",
      "|     25.29|4.71|  Male|    No| Sun|Dinner|   4|[25.29,4.0]|  0.0|\n",
      "|     35.26| 5.0|Female|    No| Sun|Dinner|   4|[35.26,4.0]|  0.0|\n",
      "|      9.55|1.45|  Male|    No| Sat|Dinner|   2| [9.55,2.0]|  0.0|\n",
      "|      9.68|1.32|  Male|    No| Sun|Dinner|   2| [9.68,2.0]|  0.0|\n",
      "|      9.94|1.56|  Male|    No| Sun|Dinner|   2| [9.94,2.0]|  0.0|\n",
      "|     10.29| 2.6|Female|    No| Sun|Dinner|   2|[10.29,2.0]|  0.0|\n",
      "|     11.24|1.76|  Male|   Yes| Sat|Dinner|   2|[11.24,2.0]|  0.0|\n",
      "|     12.54| 2.5|  Male|    No| Sun|Dinner|   2|[12.54,2.0]|  0.0|\n",
      "|     15.06| 3.0|Female|    No| Sat|Dinner|   2|[15.06,2.0]|  0.0|\n",
      "|     16.93|3.07|Female|    No| Sat|Dinner|   3|[16.93,3.0]|  0.0|\n",
      "|     17.46|2.54|  Male|    No| Sun|Dinner|   2|[17.46,2.0]|  0.0|\n",
      "|     17.78|3.27|  Male|    No| Sat|Dinner|   2|[17.78,2.0]|  0.0|\n",
      "|     18.04| 3.0|  Male|    No| Sun|Dinner|   2|[18.04,2.0]|  0.0|\n",
      "|     18.29| 3.0|  Male|    No| Sun|Dinner|   2|[18.29,2.0]|  0.0|\n",
      "|     18.35| 2.5|  Male|    No| Sat|Dinner|   4|[18.35,4.0]|  0.0|\n",
      "|     19.49|3.51|  Male|    No| Sun|Dinner|   2|[19.49,2.0]|  0.0|\n",
      "|     20.69|2.45|Female|    No| Sat|Dinner|   4|[20.69,4.0]|  0.0|\n",
      "|     24.06| 3.6|  Male|    No| Sat|Dinner|   3|[24.06,3.0]|  0.0|\n",
      "|     25.56|4.34|  Male|    No| Sun|Dinner|   4|[25.56,4.0]|  0.0|\n",
      "|     28.55|2.05|  Male|    No| Sun|Dinner|   3|[28.55,3.0]|  0.0|\n",
      "|      30.4| 5.6|  Male|    No| Sun|Dinner|   4| [30.4,4.0]|  0.0|\n",
      "|     31.27| 5.0|  Male|    No| Sat|Dinner|   3|[31.27,3.0]|  0.0|\n",
      "|      32.4| 6.0|  Male|    No| Sun|Dinner|   4| [32.4,4.0]|  0.0|\n",
      "|     34.81| 5.2|Female|    No| Sun|Dinner|   4|[34.81,4.0]|  0.0|\n",
      "|     38.01| 3.0|  Male|   Yes| Sat|Dinner|   4|[38.01,4.0]|  0.0|\n",
      "|     48.27|6.73|  Male|    No| Sat|Dinner|   4|[48.27,4.0]|  0.0|\n",
      "|     10.07|1.83|Female|    No|Thur| Lunch|   1|[10.07,1.0]|  1.0|\n",
      "|     10.51|1.25|  Male|    No| Sat|Dinner|   2|[10.51,2.0]|  0.0|\n",
      "|     11.02|1.98|  Male|   Yes| Sat|Dinner|   2|[11.02,2.0]|  0.0|\n",
      "|     13.03| 2.0|  Male|    No|Thur| Lunch|   2|[13.03,2.0]|  1.0|\n",
      "|     13.81| 2.0|  Male|   Yes| Sat|Dinner|   2|[13.81,2.0]|  0.0|\n",
      "+----------+----+------+------+----+------+----+-----------+-----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = pyspark.ml.feature.RFormula(formula='time ~ total_bill + size').fit(train)\n",
    "train_input = rf.transform(train)\n",
    "train_input.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = pyspark.ml.classification.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(lr.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_fit = lr.fit(train_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'areaUnderROC',\n",
       " 'fMeasureByLabel',\n",
       " 'fMeasureByThreshold',\n",
       " 'falsePositiveRateByLabel',\n",
       " 'featuresCol',\n",
       " 'labelCol',\n",
       " 'labels',\n",
       " 'objectiveHistory',\n",
       " 'pr',\n",
       " 'precisionByLabel',\n",
       " 'precisionByThreshold',\n",
       " 'predictionCol',\n",
       " 'predictions',\n",
       " 'probabilityCol',\n",
       " 'recallByLabel',\n",
       " 'recallByThreshold',\n",
       " 'roc',\n",
       " 'totalIterations',\n",
       " 'truePositiveRateByLabel',\n",
       " 'weightedFMeasure',\n",
       " 'weightedFalsePositiveRate',\n",
       " 'weightedPrecision',\n",
       " 'weightedRecall',\n",
       " 'weightedTruePositiveRate']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(lr_fit.summary) if not x.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area under ROC curve\n",
    "\n",
    "- Produce a curve where each point on the curve is the TP rate vs. FP rate; multiple points are found by adjusting the threshold of the model\n",
    "- The works for models that predict a probability in addition to a binary class\n",
    "- Number between 0 and 1, closer to 1 is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6526599326599328"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# area under TPR (recall) vs FPR (FP / (FP + TN)) curve\n",
    "# https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
    "lr_fit.summary.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5234521575984991"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = pyspark.ml.evaluation.BinaryClassificationEvaluator()\n",
    "test_auc = evaluator.evaluate(lr_fit.transform(rf.transform(test)))\n",
    "test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+----+------+----+-----------+-----+\n",
      "|total_bill| tip|   sex|smoker| day|  time|size|   features|label|\n",
      "+----------+----+------+------+----+------+----+-----------+-----+\n",
      "|     10.27|1.71|  Male|    No| Sun|Dinner|   2|[10.27,2.0]|  0.0|\n",
      "|     10.33|1.67|Female|    No| Sun|Dinner|   3|[10.33,3.0]|  0.0|\n",
      "|     10.34|1.66|  Male|    No| Sun|Dinner|   3|[10.34,3.0]|  0.0|\n",
      "|     15.04|1.96|  Male|    No| Sun|Dinner|   2|[15.04,2.0]|  0.0|\n",
      "|     15.77|2.23|Female|    No| Sat|Dinner|   2|[15.77,2.0]|  0.0|\n",
      "|     18.43| 3.0|  Male|    No| Sun|Dinner|   4|[18.43,4.0]|  0.0|\n",
      "|     23.68|3.31|  Male|    No| Sun|Dinner|   2|[23.68,2.0]|  0.0|\n",
      "|     26.88|3.12|  Male|    No| Sun|Dinner|   4|[26.88,4.0]|  0.0|\n",
      "|     39.42|7.58|  Male|    No| Sat|Dinner|   4|[39.42,4.0]|  0.0|\n",
      "|     13.94|3.06|  Male|    No| Sun|Dinner|   2|[13.94,2.0]|  0.0|\n",
      "|     16.04|2.24|  Male|    No| Sat|Dinner|   3|[16.04,3.0]|  0.0|\n",
      "|     16.31| 2.0|  Male|    No| Sat|Dinner|   3|[16.31,3.0]|  0.0|\n",
      "|     18.69|2.31|  Male|    No| Sat|Dinner|   3|[18.69,3.0]|  0.0|\n",
      "|     22.23| 5.0|  Male|    No| Sun|Dinner|   2|[22.23,2.0]|  0.0|\n",
      "|     26.41| 1.5|Female|    No| Sat|Dinner|   2|[26.41,2.0]|  0.0|\n",
      "|      3.07| 1.0|Female|   Yes| Sat|Dinner|   1| [3.07,1.0]|  0.0|\n",
      "|     12.02|1.97|  Male|    No| Sat|Dinner|   2|[12.02,2.0]|  0.0|\n",
      "|     15.01|2.09|  Male|   Yes| Sat|Dinner|   2|[15.01,2.0]|  0.0|\n",
      "|     16.66| 3.4|  Male|    No|Thur| Lunch|   2|[16.66,2.0]|  1.0|\n",
      "|     22.76| 3.0|  Male|    No|Thur| Lunch|   2|[22.76,2.0]|  1.0|\n",
      "+----------+----+------+------+----+------+----+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_input = rf.transform(test)\n",
    "test_input.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----+\n",
      "|prediction|0.0| 1.0|\n",
      "+----------+---+----+\n",
      "|       0.0| 40|  13|\n",
      "|       1.0|  1|null|\n",
      "+----------+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for the test data\n",
    "(lr_fit.transform(test_input)\n",
    " .select('time', 'total_bill', 'size', 'label', 'probability', 'prediction')\n",
    " .groupby('prediction') # predicted == rows\n",
    " .pivot('label') # actual values are columns\n",
    " .count()\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Binarizer',\n",
       " 'BucketedRandomProjectionLSH',\n",
       " 'BucketedRandomProjectionLSHModel',\n",
       " 'Bucketizer',\n",
       " 'ChiSqSelector',\n",
       " 'ChiSqSelectorModel',\n",
       " 'CountVectorizer',\n",
       " 'CountVectorizerModel',\n",
       " 'DCT',\n",
       " 'DecisionTreeParams',\n",
       " 'ElementwiseProduct',\n",
       " 'FeatureHasher',\n",
       " 'HasAggregationDepth',\n",
       " 'HasCheckpointInterval',\n",
       " 'HasCollectSubModels',\n",
       " 'HasDistanceMeasure',\n",
       " 'HasElasticNetParam',\n",
       " 'HasFeaturesCol',\n",
       " 'HasFitIntercept',\n",
       " 'HasHandleInvalid',\n",
       " 'HasInputCol',\n",
       " 'HasInputCols',\n",
       " 'HasLabelCol',\n",
       " 'HasLoss',\n",
       " 'HasMaxIter',\n",
       " 'HasNumFeatures',\n",
       " 'HasOutputCol',\n",
       " 'HasOutputCols',\n",
       " 'HasParallelism',\n",
       " 'HasPredictionCol',\n",
       " 'HasProbabilityCol',\n",
       " 'HasRawPredictionCol',\n",
       " 'HasRegParam',\n",
       " 'HasSeed',\n",
       " 'HasSolver',\n",
       " 'HasStandardization',\n",
       " 'HasStepSize',\n",
       " 'HasThreshold',\n",
       " 'HasThresholds',\n",
       " 'HasTol',\n",
       " 'HasVarianceCol',\n",
       " 'HasWeightCol',\n",
       " 'HashingTF',\n",
       " 'IDF',\n",
       " 'IDFModel',\n",
       " 'Imputer',\n",
       " 'ImputerModel',\n",
       " 'IndexToString',\n",
       " 'JavaEstimator',\n",
       " 'JavaMLReadable',\n",
       " 'JavaMLWritable',\n",
       " 'JavaModel',\n",
       " 'JavaParams',\n",
       " 'JavaTransformer',\n",
       " 'LSHModel',\n",
       " 'LSHParams',\n",
       " 'MaxAbsScaler',\n",
       " 'MaxAbsScalerModel',\n",
       " 'MinHashLSH',\n",
       " 'MinHashLSHModel',\n",
       " 'MinMaxScaler',\n",
       " 'MinMaxScalerModel',\n",
       " 'NGram',\n",
       " 'Normalizer',\n",
       " 'OneHotEncoder',\n",
       " 'OneHotEncoderEstimator',\n",
       " 'OneHotEncoderModel',\n",
       " 'PCA',\n",
       " 'PCAModel',\n",
       " 'Param',\n",
       " 'Params',\n",
       " 'PolynomialExpansion',\n",
       " 'QuantileDiscretizer',\n",
       " 'RFormula',\n",
       " 'RFormulaModel',\n",
       " 'RegexTokenizer',\n",
       " 'SQLTransformer',\n",
       " 'SparkContext',\n",
       " 'StandardScaler',\n",
       " 'StandardScalerModel',\n",
       " 'StopWordsRemover',\n",
       " 'StringIndexer',\n",
       " 'StringIndexerModel',\n",
       " 'Tokenizer',\n",
       " 'TypeConverters',\n",
       " 'VectorAssembler',\n",
       " 'VectorIndexer',\n",
       " 'VectorIndexerModel',\n",
       " 'VectorSizeHint',\n",
       " 'VectorSlicer',\n",
       " 'Word2Vec',\n",
       " 'Word2VecModel',\n",
       " '_CountVectorizerParams',\n",
       " '_StringIndexerParams',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_convert_to_vector',\n",
       " '_jvm',\n",
       " 'basestring',\n",
       " 'ignore_unicode_prefix',\n",
       " 'inherit_doc',\n",
       " 'keyword_only',\n",
       " 'since',\n",
       " 'sys']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Many other preprocessing steps\n",
    "dir(pyspark.ml.feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can use .first, .head, or .collect\n",
    "avg_tip_amount = train.agg(mean(\"tip\")).head()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[total_bill: double, tip: double, sex: string, smoker: string, day: string, time: string, size: bigint]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|   features|label|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2| [8.77,2.0]|  2.0|\n",
      "|     12.69| 2.0|  Male|    No|Sat|Dinner|   2|[12.69,2.0]|  2.0|\n",
      "|     13.37| 2.0|  Male|    No|Sat|Dinner|   2|[13.37,2.0]|  2.0|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|[14.78,2.0]| 3.23|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|[14.83,2.0]| 3.02|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|[15.42,2.0]| 1.57|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|[16.29,3.0]| 3.71|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|[16.97,3.0]|  3.5|\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|[16.99,2.0]| 1.01|\n",
      "|     17.81|2.34|  Male|    No|Sat|Dinner|   4|[17.81,4.0]| 2.34|\n",
      "|     17.92|4.08|  Male|    No|Sat|Dinner|   2|[17.92,2.0]| 4.08|\n",
      "|     19.65| 3.0|Female|    No|Sat|Dinner|   2|[19.65,2.0]|  3.0|\n",
      "|     19.82|3.18|  Male|    No|Sat|Dinner|   2|[19.82,2.0]| 3.18|\n",
      "|     20.29|2.75|Female|    No|Sat|Dinner|   2|[20.29,2.0]| 2.75|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|[20.65,3.0]| 3.35|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|[21.01,3.0]|  3.5|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|[21.58,2.0]| 3.92|\n",
      "|      21.7| 4.3|  Male|    No|Sat|Dinner|   2| [21.7,2.0]|  4.3|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|[24.59,4.0]| 3.61|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|[25.29,4.0]| 4.71|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = pyspark.ml.feature.RFormula(formula=\"tip ~ total_bill + size\").fit(train)\n",
    "rf.transform(train).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rawPrediction is not the same thing as binary call as the prediction is derived using the probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification baseline, create a simple logistic regression model using the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
